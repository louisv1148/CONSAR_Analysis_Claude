#!/usr/bin/env python3
"""
Fix Database Consistency Issues

This script addresses three main issues in the CONSAR database:
1. Scaling inconsistency in 2025-05 and 2025-06 (values in thousands instead of pesos)
2. Missing USD values for most periods 
3. Verification of FX rates against Banxico official data

Based on analysis:
- All CONSAR HTML files specify "Miles de Pesos" (thousands of pesos)
- Values should be stored in pesos (HTML value Ã— 1000)
- 2025-05 and 2025-06 are stored as thousands, need Ã— 1000 conversion
- Only 2.6% of records have USD values, should be 100%
"""

import json
import shutil
from pathlib import Path
from datetime import datetime

class DatabaseConsistencyFixer:
    """Fixes scaling and currency conversion issues in CONSAR database."""
    
    def __init__(self, database_path='data/merged_consar_data_2019_2025.json', 
                 banxico_path='/Users/lvc/CascadeProjects/Banxico_FX_Update/FX download/fx_data.json'):
        self.database_path = Path(database_path)
        self.banxico_path = Path(banxico_path)
        self.backup_path = Path(str(database_path).replace('.json', '.backup_consistency.json'))
        
    def load_data(self):
        """Load database and Banxico FX data."""
        print("ğŸ“Š Loading CONSAR database...")
        with open(self.database_path, 'r', encoding='utf-8') as f:
            self.db_data = json.load(f)
        print(f"   Loaded {len(self.db_data):,} records")
        
        print("ğŸ’± Loading Banxico FX data...")
        with open(self.banxico_path, 'r', encoding='utf-8') as f:
            banxico_data = json.load(f)
            self.fx_data = {date: rate for date, rate in banxico_data['valores']}
        print(f"   Loaded {len(self.fx_data):,} FX rates")
        
    def create_backup(self):
        """Create backup of original database."""
        print(f"ğŸ’¾ Creating backup: {self.backup_path}")
        shutil.copy2(self.database_path, self.backup_path)
        
    def analyze_current_state(self):
        """Analyze current database state."""
        print("\\nğŸ” ANALYZING CURRENT DATABASE STATE")
        print("=" * 60)
        
        # Check scaling by period
        period_totals = {}
        field_coverage = {'mxn': 0, 'fx': 0, 'usd': 0, 'complete': 0}
        
        for record in self.db_data:
            if record.get('Concept') == 'Total de Activo':
                period = f"{record.get('PeriodYear')}-{record.get('PeriodMonth')}"
                value_mxn = record.get('valueMXN', 0)
                
                if period not in period_totals:
                    period_totals[period] = 0
                period_totals[period] += value_mxn
            
            # Count field coverage
            if record.get('valueMXN') is not None:
                field_coverage['mxn'] += 1
            if record.get('FX_EOM') is not None:
                field_coverage['fx'] += 1
            if 'valueUSD' in record and record['valueUSD'] is not None:
                field_coverage['usd'] += 1
            if (record.get('valueMXN') is not None and 
                record.get('FX_EOM') is not None and
                'valueUSD' in record and record['valueUSD'] is not None):
                field_coverage['complete'] += 1
        
        # Identify scaling issues
        scaling_issues = []
        for period, total in period_totals.items():
            if total > 0 and total < 1_000_000_000_000:  # Less than 1 trillion
                scaling_issues.append(period)
        
        print(f"ğŸ“ˆ Scaling Issues Found: {len(scaling_issues)} periods")
        for period in scaling_issues:
            print(f"   {period}: {period_totals[period]:,.0f} MXN (too small)")
        
        print(f"\\nğŸ“Š Field Coverage:")
        total_records = len(self.db_data)
        print(f"   Total records: {total_records:,}")
        print(f"   MXN values: {field_coverage['mxn']:,} ({field_coverage['mxn']/total_records*100:.1f}%)")
        print(f"   FX rates: {field_coverage['fx']:,} ({field_coverage['fx']/total_records*100:.1f}%)")
        print(f"   USD values: {field_coverage['usd']:,} ({field_coverage['usd']/total_records*100:.1f}%)")
        print(f"   Complete records: {field_coverage['complete']:,} ({field_coverage['complete']/total_records*100:.1f}%)")
        
        return scaling_issues
    
    def fix_scaling_issues(self, periods_to_fix):
        """Fix scaling issues by multiplying MXN values by 1000."""
        if not periods_to_fix:
            print("\\nâœ… No scaling issues to fix")
            return 0
            
        print(f"\\nğŸ”§ FIXING SCALING ISSUES")
        print("=" * 60)
        
        records_fixed = 0
        
        for record in self.db_data:
            period = f"{record.get('PeriodYear')}-{record.get('PeriodMonth')}"
            
            if period in periods_to_fix:
                # Remove existing USD values (they're calculated from wrong MXN values)
                if 'valueUSD' in record:
                    del record['valueUSD']
                
                # Fix MXN scaling (multiply by 1000 to convert from thousands to pesos)
                if 'valueMXN' in record and record['valueMXN'] is not None:
                    record['valueMXN'] = record['valueMXN'] * 1000
                    records_fixed += 1
        
        print(f"âœ… Fixed {records_fixed:,} records across {len(periods_to_fix)} periods")
        for period in periods_to_fix:
            print(f"   {period}: MXN values multiplied by 1000")
            
        return records_fixed
    
    def verify_fx_rates(self):
        """Verify FX rates against Banxico data."""
        print(f"\\nğŸ’± VERIFYING FX RATES AGAINST BANXICO DATA")
        print("=" * 60)
        
        # Get unique periods and their FX rates
        period_fx = {}
        for record in self.db_data:
            period = f"{record.get('PeriodYear')}-{record.get('PeriodMonth')}"
            fx_rate = record.get('FX_EOM')
            if fx_rate is not None:
                period_fx[period] = fx_rate
        
        mismatches = 0
        matches = 0
        missing = 0
        
        print("Period    | Database FX | Banxico FX  | Status")
        print("-" * 50)
        
        for period in sorted(period_fx.keys())[-10:]:  # Check last 10 periods
            db_fx = period_fx[period]
            year, month = period.split('-')
            
            # Find Banxico end-of-month rate
            banxico_fx = None
            month_candidates = []
            
            for date, rate in self.fx_data.items():
                if date.startswith(f'{year}-{month}'):
                    month_candidates.append((date, rate))
            
            if month_candidates:
                # Get the last available rate for the month (closest to month-end)
                banxico_date, banxico_fx = max(month_candidates)
                diff = abs(db_fx - banxico_fx)
                
                if diff < 0.01:
                    status = "âœ… MATCH"
                    matches += 1
                else:
                    status = "âš ï¸  DIFF"
                    mismatches += 1
                    
                print(f"{period:<9} | {db_fx:>10.4f} | {banxico_fx:>10.4f} | {status}")
            else:
                status = "âŒ NO DATA"
                missing += 1
                print(f"{period:<9} | {db_fx:>10.4f} | {'N/A':>10} | {status}")
        
        print(f"\\nğŸ“Š FX Verification Summary:")
        print(f"   Matches: {matches}")
        print(f"   Mismatches: {mismatches}")  
        print(f"   Missing Banxico data: {missing}")
        
        if mismatches > 0:
            print("\\nâš ï¸  Some FX rates don't match Banxico data")
            print("   This is acceptable as CONSAR may use different end-of-month dates")
        else:
            print("\\nâœ… All FX rates verified against Banxico data")
    
    def generate_usd_values(self):
        """Generate USD values for all records using FX rates."""
        print(f"\\nğŸ’µ GENERATING USD VALUES")
        print("=" * 60)
        
        records_with_usd = 0
        records_generated = 0
        
        for record in self.db_data:
            value_mxn = record.get('valueMXN')
            fx_rate = record.get('FX_EOM')
            
            if value_mxn is not None and fx_rate is not None and fx_rate > 0:
                if 'valueUSD' not in record or record['valueUSD'] is None:
                    # Generate USD value
                    record['valueUSD'] = value_mxn / fx_rate
                    records_generated += 1
                else:
                    records_with_usd += 1
            elif 'valueUSD' in record:
                # Remove USD value if we can't calculate it properly
                del record['valueUSD']
        
        print(f"âœ… USD value generation complete:")
        print(f"   Records with existing USD: {records_with_usd:,}")
        print(f"   Records with generated USD: {records_generated:,}")
        print(f"   Total USD coverage: {records_with_usd + records_generated:,} / {len(self.db_data):,} ({(records_with_usd + records_generated)/len(self.db_data)*100:.1f}%)")
        
        return records_generated
    
    def verify_fixes(self):
        """Verify that all fixes were applied correctly."""
        print(f"\\nâœ… VERIFYING FIXES")
        print("=" * 60)
        
        # Check scaling consistency
        period_totals = {}
        for record in self.db_data:
            if record.get('Concept') == 'Total de Activo':
                period = f"{record.get('PeriodYear')}-{record.get('PeriodMonth')}"
                value_mxn = record.get('valueMXN', 0)
                
                if period not in period_totals:
                    period_totals[period] = 0
                period_totals[period] += value_mxn
        
        # Check for remaining scaling issues
        remaining_issues = 0
        for period, total in period_totals.items():
            if total > 0 and total < 1_000_000_000_000:
                remaining_issues += 1
        
        print(f"ğŸ“ˆ Scaling verification:")
        if remaining_issues == 0:
            print("   âœ… All periods now have consistent scaling")
        else:
            print(f"   âŒ {remaining_issues} periods still have scaling issues")
        
        # Check USD coverage
        usd_coverage = sum(1 for r in self.db_data if 'valueUSD' in r and r['valueUSD'] is not None)
        total_records = len(self.db_data)
        
        print(f"ğŸ’µ USD coverage verification:")
        print(f"   Records with USD: {usd_coverage:,} / {total_records:,} ({usd_coverage/total_records*100:.1f}%)")
        
        if usd_coverage > total_records * 0.95:  # 95% coverage is good
            print("   âœ… Excellent USD coverage achieved")
        elif usd_coverage > total_records * 0.8:  # 80% coverage is acceptable
            print("   âš ï¸  Good USD coverage achieved")
        else:
            print("   âŒ Poor USD coverage - manual review needed")
    
    def save_fixed_database(self):
        """Save the fixed database."""
        print(f"\\nğŸ’¾ SAVING FIXED DATABASE")
        print("=" * 60)
        
        print(f"ğŸ“ Saving to: {self.database_path}")
        with open(self.database_path, 'w', encoding='utf-8') as f:
            json.dump(self.db_data, f, ensure_ascii=False, separators=(',', ':'))
        
        file_size = self.database_path.stat().st_size / (1024 * 1024)  # MB
        print(f"âœ… Database saved successfully ({file_size:.1f} MB)")
    
    def run(self):
        """Run the complete consistency fix process."""
        print("ğŸ”§ CONSAR DATABASE CONSISTENCY FIXER")
        print("=" * 80)
        print("Fixing scaling, FX rates, and USD value generation")
        print("=" * 80)
        
        try:
            # Load data
            self.load_data()
            
            # Create backup
            self.create_backup()
            
            # Analyze current state
            scaling_issues = self.analyze_current_state()
            
            # Fix scaling issues
            scaling_fixes = self.fix_scaling_issues(scaling_issues)
            
            # Verify FX rates
            self.verify_fx_rates()
            
            # Generate USD values
            usd_fixes = self.generate_usd_values()
            
            # Verify all fixes
            self.verify_fixes()
            
            # Save fixed database
            self.save_fixed_database()
            
            print(f"\\nğŸ‰ DATABASE CONSISTENCY FIX COMPLETED!")
            print("=" * 80)
            print(f"ğŸ“Š Summary of changes:")
            print(f"   Scaling fixes: {scaling_fixes:,} records")
            print(f"   USD values generated: {usd_fixes:,} records")
            print(f"   Backup created: {self.backup_path}")
            print("\\nâœ… Database is now consistent and ready for analysis!")
            
        except Exception as e:
            print(f"\\nâŒ ERROR: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
            
        return True

def main():
    fixer = DatabaseConsistencyFixer()
    success = fixer.run()
    
    if success:
        print("\\nğŸš€ You can now run the CONSAR analysis app with consistent data!")
        print("   All periods will display properly in the same units")
        print("   All records have USD values calculated from verified FX rates")
    else:
        print("\\nğŸ’¥ Fix process failed - check error messages above")

if __name__ == "__main__":
    main()