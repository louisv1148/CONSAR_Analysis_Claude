#!/usr/bin/env python3
"""
Validate Definitive Database Integrity

Quick validation script to ensure the definitive database maintains its integrity.
Run this before using the database for analysis or after any updates.
"""

import json
from pathlib import Path
import sys

def validate_definitive_database():
    """Validate the definitive database integrity."""
    
    # Find the project root directory (where data folder is located)
    script_dir = Path(__file__).parent
    project_root = script_dir.parent.parent
    database_path = project_root / 'data/merged_consar_data_2019_2025.json'
    
    print("üîç VALIDATING DEFINITIVE CONSAR DATABASE")
    print("=" * 50)
    
    # Check if file exists
    if not database_path.exists():
        print("‚ùå CRITICAL: Database file not found!")
        return False
    
    try:
        # Load database
        with open(database_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"üìä Records loaded: {len(data):,}")
        
        # Test 1: Check scaling consistency
        print("\n1Ô∏è‚É£ Testing scaling consistency...")
        period_totals = {}
        for record in data:
            if record.get('Concept') == 'Total de Activo':
                period = f"{record.get('PeriodYear')}-{record.get('PeriodMonth')}"
                value_mxn = record.get('valueMXN', 0)
                
                if period not in period_totals:
                    period_totals[period] = 0
                period_totals[period] += value_mxn
        
        # Check critical periods that had scaling issues
        critical_periods = ['2024-12', '2025-05', '2025-06']
        scaling_ok = True
        
        for period in critical_periods:
            if period in period_totals:
                total = period_totals[period]
                if total < 1_000_000_000_000:  # Less than 1 trillion
                    print(f"   ‚ùå {period}: {total:,.0f} MXN (TOO SMALL)")
                    scaling_ok = False
                else:
                    print(f"   ‚úÖ {period}: {total:,.0f} MXN")
            else:
                print(f"   ‚ö†Ô∏è  {period}: No data found")
        
        if scaling_ok:
            print("   ‚úÖ Scaling consistency: PASSED")
        else:
            print("   ‚ùå Scaling consistency: FAILED")
            return False
        
        # Test 2: Check USD coverage
        print("\n2Ô∏è‚É£ Testing USD coverage...")
        usd_count = sum(1 for r in data if 'valueUSD' in r and r['valueUSD'] is not None)
        coverage_pct = usd_count / len(data) * 100
        
        print(f"   USD records: {usd_count:,} / {len(data):,} ({coverage_pct:.1f}%)")
        
        if coverage_pct >= 99.0:
            print("   ‚úÖ USD coverage: EXCELLENT")
        elif coverage_pct >= 95.0:
            print("   ‚ö†Ô∏è  USD coverage: GOOD (but not optimal)")
        else:
            print("   ‚ùå USD coverage: POOR")
            return False
        
        # Test 3: Check FX rate presence
        print("\n3Ô∏è‚É£ Testing FX rate coverage...")
        fx_count = sum(1 for r in data if r.get('FX_EOM') is not None)
        fx_coverage_pct = fx_count / len(data) * 100
        
        print(f"   FX records: {fx_count:,} / {len(data):,} ({fx_coverage_pct:.1f}%)")
        
        if fx_coverage_pct == 100.0:
            print("   ‚úÖ FX coverage: PERFECT")
        else:
            print("   ‚ùå FX coverage: INCOMPLETE")
            return False
        
        # Test 4: Mathematical consistency check
        print("\n4Ô∏è‚É£ Testing USD calculation accuracy...")
        math_errors = 0
        sample_size = min(1000, len(data))
        
        for i, record in enumerate(data[:sample_size]):
            value_mxn = record.get('valueMXN')
            value_usd = record.get('valueUSD')
            fx_rate = record.get('FX_EOM')
            
            if value_mxn is not None and value_usd is not None and fx_rate is not None and fx_rate > 0:
                calculated_usd = value_mxn / fx_rate
                if abs(value_usd - calculated_usd) > 1.0:  # Allow 1 USD difference for rounding
                    math_errors += 1
        
        if math_errors == 0:
            print(f"   ‚úÖ Mathematical accuracy: PERFECT (tested {sample_size:,} records)")
        else:
            print(f"   ‚ùå Mathematical accuracy: {math_errors} errors in {sample_size:,} records")
            return False
        
        # Test 5: Required fields check
        print("\n5Ô∏è‚É£ Testing required fields...")
        required_fields = ['Afore', 'Siefore', 'Concept', 'valueMXN', 'PeriodYear', 'PeriodMonth', 'FX_EOM']
        missing_fields = 0
        
        for record in data:
            for field in required_fields:
                if field not in record or record[field] is None:
                    missing_fields += 1
                    break
        
        if missing_fields == 0:
            print("   ‚úÖ Required fields: ALL PRESENT")
        else:
            print(f"   ‚ùå Required fields: {missing_fields} records missing fields")
            return False
        
        print("\nüéâ VALIDATION RESULT: DATABASE IS VALID")
        print("=" * 50)
        print("‚úÖ This database is ready for production use")
        print("‚úÖ All consistency checks passed")
        print("‚úÖ Safe to use for analysis and reporting")
        
        return True
        
    except json.JSONDecodeError:
        print("‚ùå CRITICAL: Database file is corrupted (invalid JSON)")
        return False
    except Exception as e:
        print(f"‚ùå CRITICAL: Validation failed with error: {str(e)}")
        return False

def main():
    """Main validation function."""
    if validate_definitive_database():
        print("\nüöÄ Ready to run CONSAR analysis!")
        sys.exit(0)
    else:
        print("\nüí• Database validation failed!")
        print("‚ö†Ô∏è  DO NOT use this database for analysis")
        print("üîß Run fix_database_consistency.py to repair")
        sys.exit(1)

if __name__ == "__main__":
    main()